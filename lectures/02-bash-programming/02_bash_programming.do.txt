TITLE: Basic Bash programming
# #include "authors.do.txt"
DATE: today

!split
======= Some more course information =======
.

!split
===== Reminder: Sign up to Piazza =====

  * Great knowledge and discussion platform.
  * Allows students to ask and answer questions.
  * Lecturers/teaching assistants will be active on the platform as well.
  * We will announce course updates (for example the video recordings).
  * Sign up: "http://piazza.com/uio.no/fall2016/inf3331inf4331":"http://piazza.com/uio.no/fall2016/inf3331inf4331"

!split
===== Assignment 1 =====

  * Deadline: Extended to this Friday
  * Make sure that your solutions are pushed to your github repository.

    All files should be in

    https://github.com/UiO-INF3331/INF3331-<UiO-Username>

!split
===== Assignments 2 =====

  * Assignment 2 is online now.
  * Topic: Bash scripting (lecture today).

!split
======= Basic Bash programming =======
.

!split
===== Overview of Unix shells =====

  * The original scripting languages were (extensions of) command interpreters in operating systems
  * Primary example: Unix shells
  * Bourne shell (`sh`) was the first major shell
  * C and TC shell (`csh` and `tcsh`) had improved command interpreters, but were less popular than Bourne shell for programming
  * Bourne Again shell (Bash/`bash`): GNU/FSF improvement of Bourne shell
  * Other Bash-like shells: Dash (`dash`), Korn shell (`ksh`), Z shell (`zsh`)
  * Bash is the dominating Unix shell today

!split
===== Why learn Bash? =====

  * Learning Bash means learning Unix
  * Learning Bash means learning the roots of scripting (Bourne shell is a subset of Bash)
  * Shell scripts, especially in Bourne shell and Bash, are frequently encountered on Unix systems
  * Bash is widely available (open source) and the dominating command interpreter and scripting language on today's Unix systems

!split
===== Why learn Bash? (2) =====

  * Shell scripts evolve naturally from a workflow: \begin{enumerate}
  * A sequence of commands you use often are placed in a file
  * Command-line options are introduced to enable different options to be passed to the commands
  * Introducing variables, if tests, loops enables more complex program flow
  * At some point pre- and postprocessing becomes too advanced for bash, at which point (parts of) the script should be ported to Python or other tools \end{enumerate}
  * Shell scripts are often used to glue more advanced scripts in Perl and Python

!split
===== Remark =====

  * The plain Bourne shell can be used (`/bin/sh`) when special features of Bash (`/bin/bash`) are not needed
  * Most of our examples can in fact be run under Bourne shell (and of course also Bash).
  * In Mac OSX, the Bourne shell (`/bin/sh`) is just a link to Bash
    (`/bin/bash`). In Ubuntu, the Bourne shell (`/bin/sh`) is a link to Dash, a
    minimal, but much faster shell than bash.

!split
===== More information =====

  * Offline documentation: `man bash`
  * Bash reference manual: http://www.gnu.org/software/bash/manual/bashref.html
  * Advanced Bash-Scripting Guide: http://www.tldp.org/LDP/abs/html
  * Simple and good tutorial: http://www.linuxintro.org/wiki/Shell_scripting_tutorial

!split
===== What Bash is good for =====

  * File and directory management
  * Systems management (build scripts)
  * Combining other scripts and commands
  * Rapid prototyping of more advanced scripts
  * Very simple output processing, plotting etc.

!split
===== What Bash is not good for =====

  * Cross-platform portability
  * Graphics, GUIs
  * Interface with libraries or legacy code
  * More advanced post processing and plotting
  * Calculations, math etc.

!split
===== Some common tasks in Bash =====

  * file writing
  * for-loops
  * running an application
  * pipes
  * writing functions
  * file globbing, testing file types
  * copying and renaming files, creating and moving to directories, creating directory paths, removing files and directories
  * directory tree traversal
  * packing directory trees

!split
===== Bash example 1: Hello world =====

!bc bash
#!/bin/bash
echo "Hello world"
!ec

Two options to run this script:

  * Type the commands directly in the bash shell (only feasible for small scripts).
  * Save the code as `helloworld.sh` and run with:
!bc bash
chmod a+x helloworld.sh  # Make script executable
./helloworld.sh
!ec


!split
===== Bash example 2: Hello world, v2 =====

!bc bash
#!/bin/bash
x="world"
echo "Hello ${x}!"
!ec

!split
===== Bash example 3: Line counter =====

!bc bash
#!/bin/bash
filename="text.txt"
declare -i count; count=0

echo "Start counting..."
# loop over all lines of  file
while read p; do
    # increase line counter
    ((count++))
done < $filename
echo "done"

echo "Number of lines in $file: ${count}"
!ec



!split
===== Bash variables and commands =====

  * Assign a variable by `x=3.4`, retrieve the value of the variable by `$x` or `${x}` (also called *variable substitution*).
  * Variables passed as command line arguments when running a script are called `positional parameters`.
  * Bash has a number of built in commands.

    Type `help` or `help | less` to get a list.

  * The real power comes from all the available Unix commands, in addition to your own applications and scripts.

    Try:
!bc bash
curl -s http://www.yr.no/place/Norway/Oslo/Oslo/Oslo/ |
    grep -m 1 "temperature" | cut -d"\"" -f4
!ec




!split
===== Bash variables (1) =====


Variables in Bash are untyped!

Generally treated as character arrays, but permit simple
  arithmetic and other operations

Variables can be explicitly declared to integer or array;

!bc shcod
declare -i i     # i is an integer
declare -a A     # A is an array
declare -r r=10  # r is read only
!ec






!split
===== Bash variables (2) =====


The `echo` command is used for writing:

!bc shcod
s=42
echo "The answer is $s"
!ec
and variables can be inserted in the text string (variable interpolation)

Frequently seen variables:


  * Command line arguments:
!bc shcod
$1  $2  $3  $4 and so on
!ec

  * All command line arguments as array: `$@`
  * Number of command line arguments: `$#`
  * The exit status of the last executed command: `$?` (is 0 if command was succesfull)



!split
===== Bash variables (3) =====


Comparison of two integers use a syntax different from comparison of two strings:


!bc shcod
if [ $i -eq 10 ]; then        # integer comparison
if [ "$name" == "10" ]; then  # string  comparison
!ec


Unless you have declared a variable to be an integer, assume that all variables are strings and use double quotes (strings) when comparing variables in an if test


!bc shcod
if [ "$?" != "0" ]; then  # this is safe
if [  $?  !=  0  ]; then  # might be unsafe
!ec


!split
===== Convenient debugging tool: -x =====


Each source code line is printed prior to its execution if you add -x as option to `/bin/bash`

Either in the header


!bc shcod
#!/bin/bash -x
!ec

or on the command line:


!bc shcod
unix> /bin/bash -x hw.sh
unix> sh -x hw.sh  # only works if sh links to bash
unix> bash -x hw.sh
!ec


Very convenient during debugging





!split
===== Combining bash commands (1) =====

  * The power of Unix lies in combining simple commands into powerful operations
  * Standard bash commands and Unix applications normally do one small task
  * Text is used for input and output -- easy to send output from one command as input to another

!split
===== Combining bash commands (2) =====
Two standard ways to combine commands:


  * The pipe, sends the output of one command as input to the next:

!bc shcod
ls -l | grep 3331
!ec
Will list all files having 3331 as part of the name

  * Executing a command, storing the result as a variable:

!bc shcod
time=$(date)
# or time=`date`
echo $time
!ec




!split
===== Combining bash commands (3) =====


More useful applications of pipes:


!bc shcod
# send files with size to sort -rn
# (reverse numerical sort) to get a list
# of files sorted after their sizes:

/bin/ls -s | sort -rn


cat $case.i | oscillator
# is the same as
oscillator < $case.i
!ec


Make a new application: sort all files in a directory
tree `root`, with the largest files appearing first, and
equip the output with paging functionality:


!bc shcod
du -a root | sort -rn | less
!ec


!split
===== Bash redirects =====

Redirects are used to pass output to either a file or stream.
!bc shcod
echo "Hei verden" > myfile.txt  # Save output to file
wc -w < myfile.txt   # Use file content as command input
!ec

Note: Pipes can be (in an inefficient way) reimplemented with redirects:
!bc shcod
prog1 > myfile && prog2 < myfile
!ec
is the same as
!bc shcod
prog1 | prog2
!ec

!split
===== Redirects and stdin, stdout, stderr =====

!bc shcod
rm -v *.txt 1> out.txt      # Redirect stout to a file
rm -v *.txt 2> err.txt      # Redirect stderr to a file
rm -v *.txt &> outerr.txt   # Redirect stdout and stderr to file
rm -v *.txt 1>&2            # Redirect stdout to stderr
rm -v *.txt 2>&1            # Redirect stderr to stdout
!ec

You can print to stderr with:
!bc shcod
echo "Wrong arguments" >&2
!ec

Redirects and pipes can be combined:
!bc shcod
./compile 2>&1 | less  # View both stdout and stderr in less
!ec






!split
===== Example: the classical Unix script =====
A combination of commands, or a single long command, that you use often;

!bc shcod
./pulse_app -cmt WinslowRice -casename ellipsoid
    < ellipsoid.i | tee main_output
!ec
(should be a single line)
In this case, flexibility is often not a high priority. However, there
is room for improvement;

  * Not possible to change command line options, input and output files
  * Output file `main_output` is overwritten for each run
  * Can we edit the input file for each run?

!split
===== Problem 1; changing application input =====
In many cases only one parameter is changed frequently;

!bc shcod
CASE='testbox'
CMT='WinslowRice'
if [ $# -gt 0 ]; then
   CMT=$1
fi
INFILE='ellipsoid_test.i'
OUTFILE='main_output'

./pulse_app -cmt $CMT -cname $CASE
  < $INFILE | tee $OUTFILE
!ec
Still not very flexible, but in many cases sufficient. More
flexibility requires more advanced parsing of command line options,
which will be introduced later.


!split
===== Problem 2; overwriting output file =====


A simple solution is to add the output file as a command line
  option, but what if we forget to change this from one run to the
  next?

Simple solution to ensure data is never over-written:

!bc shcod
jobdir=$PWD/$(date)
mkdir $jobdir
cd $jobdir

./pulse_app -cmt $CMT -cname $CASE  < $INFILE | tee $OUTFILE
cd ..
if [ -L 'latest' ]; then
    rm latest
fi
ln -s $jobdir latest
!ec



!split
===== Problem 2; overwriting output file (2) =====
Alternative solutions;


* Use process ID of the script (`$$`, not really unique)

* `mktemp` can create a temporary file with a unique name, for
  use by the script
* Check if subdirectory exists, exit script if it does;
!bc shcod
dir=$case
# check if $dir is a directory:
if [ -d $dir ]
  #exit script to avoid overwriting data
  then
    echo "Output directory exists, provide a different name"
    exit
fi
mkdir $dir   # create new directory $dir
cd $dir      # move to $dir

!ec

!split
===== Alternative `if`-tests =====
As with everything else in Bash, there are multiple ways to do `if`-tests:

!bc shcod

# the 'then' statement can also appear on the next line:
if [ -d $dir ]; then
  exit
fi

# another form of if-tests:
if test -d $dir; then
  exit
fi

# and a shortcut:
[ -d $dir ] && exit
test -d $dir && exit
!ec





!split
===== Problem 3; can we edit the input file at run time? =====

  * Some applications do not take command line options, all input must read from standard input or an input file
  * A Bash script can be used to equip such programs with basic handling of command line options
  * We want to grab input from the command line, create the correct input file, and run the application

!split
===== File reading and writing =====


File writing is efficiently done by 'here documents':


!bc shcod
cat > myfile <<EOF
multi-line text
can now be inserted here,
and variable substition such as
$myvariable is
supported.
EOF
!ec
The final EOF must
start in column 1 of the
script file.

EOF is an arbitrary keyword here.




!split
===== Parsing command-line options =====


!bc shcod
# read variables from the command line, one by one:
while [ $# -gt 0 ]  # $# = no of command-line args.
do
    option=$1; # load command-line arg into option
    shift;       # eat currently first command-line arg
    case "$option" in
        -m)
            m=$1; shift; ;;  # ;; indicates end of case
        -b)
            b=$1; shift; ;;
        	...
        *)
            echo "$0: invalid option \"$option\""; exit ;;
    esac
done
!ec



!split
===== Alternative to case: if =====

`case` is standard when parsing command-line arguments in Bash, but if-tests can also be used. Consider


!bc shcod
   case "$option" in
       -m)
           m=$1; shift; ;;  # load next command-line arg
       -b)
           b=$1; shift; ;;
       *)
           echo "$0: invalid option \"$option\""; exit ;;
    esac
!ec

versus


!bc shcod
    if [ "$option" == "-m" ]; then
        m=$1; shift;  # load next command-line arg
    elif [ "$option" == "-b" ]; then
        b=$1; shift;
    else
        echo "$0: invalid option \"$option\""; exit
    fi

echo "Command line arguments:"
[ -n "$m" ] && echo "m=$m"
[ -n "$b" ] && echo "b=$b"
!ec



!split
===== After assigning variables, we can write the input file =====
!bc shcod
# write to $infile the lines that appear between
# the EOF symbols:

cat > $infile <<EOF
        gridfile='test2.grid'
        param_a=4.5
EOF
!ec



!split
===== Then execute the program as usual =====


Redirecting input to read from the new input file

!bc shcod
../pulse_app < $infile
!ec

We can add a check for successful execution.
The shell variable `$?` is 0 if last command
was successful, otherwise `$? != 0`.

!bc shcod
if [ "$?" != "0" ]; then
  echo "running pulse_app failed"; exit 1
fi

# exit n sets $? to n
!ec






!split
===== Other uses of `cat` =====

!bc shcod
cat myfile             # write myfile to the screen
cat myfile >  yourfile # write myfile to yourfile
cat myfile >> yourfile # append myfile to yourfile
cat myfile | wc        # send myfile as input to wc
!ec



!split
===== For-loops =====


What if we want to run the application for multiple input files?

!bc shcod
./run.sh test1.i test2.i test3.i test4.i
!ec
or

!bc shcod
./run.sh *.i
!ec

A for-loop over command line arguments

!bc shcod
for arg in $@; do
  ../../build/app/pulse_app < $arg
done
!ec

Can be combined with more advanced command line options, output
  directories, etc...




!split
===== For-loops (2) =====


For loops for file management:


!bc shcod
files=`ls *.tmp`

for file in $files
do
  echo removing $file
  rm -f $file
done
!ec




!split
===== Counters =====


Declare an integer counter:


!bc shcod
declare -i counter
counter=0
# arithmetic expressions must appear inside (( ))
((counter++))
echo $counter  # yields 1
!ec

For-loop with counter:


!bc shcod
declare -i n; n=1
for arg in $@; do
  echo "command-line argument no. $n is <$arg>"
  ((n++))
done
!ec





!split
===== C-style for-loops =====


!bc shcod
declare -i i
for ((i=0; i<$n; i++)); do
  echo $c
done
!ec



!split
===== Example: bundle files =====


Idea:
  * Scripts packs a series of files into one file
  * Executing this single file as a Bash script packs out all the individual files again

Usage:


!bc shcod
bundle file1 file2 file3 > onefile  # pack
bash onefile # unpack
!ec


Writing `bundle` is easy:


!bc shcod
#/bin/bash
for i in $@; do
    echo "echo unpacking file $i"
    echo "cat > $i <<EOF"
    cat $i
    echo "EOF"
done
!ec





!split
===== The bundle output file =====


Consider 2 fake files; file1


!bc shcod
Hello, World!
No sine computations today
!ec

and file2


!bc shcod
1.0 2.0 4.0
0.1 0.2 0.4
!ec


Running `bundle file1 file2` yields the output


!bc shcod
echo unpacking file file1
cat > file1 <<EOF
Hello, World!
No sine computations today
EOF
echo unpacking file file2
cat > file2 <<EOF
1.0 2.0 4.0
0.1 0.2 0.4
EOF
!ec





!split
===== Running an application =====


Running in the foreground:


!bc shcod
cmd="myprog -c file.1 -p -f -q";
$cmd < my_input_file

# output is directed to the file res
$cmd < my_input_file > res

# process res file by Sed, Awk, Perl or Python
!ec


Running in the background:


!bc shcod
myprog -c file.1 -p -f -q < my_input_file &
!ec

or stop a foreground job with Ctrl-Z and then type `bg`






!split
===== Functions =====


!bc shcod
function system {
# Run operating system command and if failure, report and abort

  "$@"
  if [ $? -ne 0 ]; then
    echo "make.sh: unsuccessful command $@"
    echo "abort!"
    exit 1
  fi
}
# function arguments: $1 $2 $3 and so on
# return value: last statement
# call:
name=mydoc
system pdflatex $name
system bibtex $name
!ec

How to return a value from a function? Define a new variable within the function - all functions are global!



!split
===== File globbing, for loop on the command line =====


List all .ps and .gif files using wildcard notation:


!bc shcod
files=`ls *.ps *.gif`

# or safer, if you have aliased ls:
files=`/bin/ls *.ps *.gif`

# compress and move the files:
gzip $files
for file in $files; do
  mv ${file}.gz $HOME/images
!ec





!split
===== Testing file types =====


!bc shcod
if [ -f $myfile ]; then
    echo "$myfile is a plain file"
fi

# or equivalently:
if test -f $myfile; then
    echo "$myfile is a plain file"
fi

if [ ! -d $myfile ]; then
    echo "$myfile is NOT a directory"
fi

if [ -x $myfile ]; then
    echo "$myfile is executable"
fi

[ -z $myfile ] && echo "empty file $myfile"
!ec



!split
===== Rename, copy and remove files =====


!bc shcod
# rename $myfile to tmp.1:
mv $myfile tmp.1

# force renaming:
mv -f $myfile tmp.1

# move a directory tree my tree to $root:
mv mytree $root

# copy myfile to $tmpfile:
cp myfile $tmpfile

# copy a directory tree mytree recursively to $root:
cp -r mytree $root

# remove myfile and all files with suffix .ps:
rm myfile *.ps

# remove a non-empty directory tmp/mydir:
rm -r tmp/mydir
!ec



!split
===== Directory management =====


!bc shcod
# make directory:
$dir = "mynewdir";
mkdir $mynewdir
mkdir -m 0755 $dir  # readable for all
mkdir -m 0700 $dir  # readable for owner only
mkdir -m 0777 $dir  # all rights for all

cd $dir # move to $dir
cd      # move to $HOME

# create intermediate directories (the whole path):
mkdir -p  $HOME/bash/prosjects/test1
!ec



!split
===== The find command =====

Very useful command!


`find` visits all files in a directory tree and can execute one or more commands for every file

Basic example: find the `oscillator` codes


!bc shcod
find $scripting/src -name 'oscillator*' -print
!ec


Or find all PostScript files


!bc shcod
find $HOME \( -name '*.ps' -o -name '*.eps' \) -print
!ec


We can also run a command for each file:


!bc shcod
find rootdir -name filenamespec -exec command {} \; -print
# {} is the current filename
!ec





!split
===== Applications of find (1) =====


Find all files larger than 2000 blocks a 512 bytes (=1Mb):


!bc shcod
find $HOME -name '*' -type f -size +2000 -exec ls -s {} \;
!ec


Remove all these files:


!bc shcod
find $HOME -name '*' -type f -size +2000 \
     -exec ls -s {} \; -exec rm -f {} \;
!ec

or ask the user for permission to remove:


!bc shcod
find $HOME -name '*' -type f -size +2000 \
     -exec ls -s {} \; -ok rm -f {} \;
!ec





!split
===== Applications of find (2) =====


Find all files not being accessed for the last 90 days:


!bc shcod
find $HOME -name '*' -atime +90 -print
!ec

and move these to /tmp/trash:


!bc shcod
find $HOME -name '*' -atime +90 -print \
     -exec mv -f {} /tmp/trash \;
!ec






!split
===== Tar and gzip =====


The `tar` command can pack single files or  all files in a directory tree into one file, which can be unpacked later


!bc shcod
tar -cvf myfiles.tar mytree file1 file2

# options:
# c: pack, v: list name of files, f: pack into file

# unpack the mytree tree and the files file1 and file2:
tar -xvf myfiles.tar

# options:
# x: extract (unpack)
!ec


The tarfile can be compressed:


!bc shcod
gzip mytar.tar

# result: mytar.tar.gz
!ec


!split
===== Two find/tar/gzip examples =====


Pack all PostScript figures:


!bc shcod
tar -cvf ps.tar `find $HOME -name '*.ps' -print`
gzip ps.tar
!ec


Pack a directory but remove CVS directories and redundant files


!bc shcod
# take a copy of the original directory:
cp -r myhacks /tmp/oblig1-hpl
# remove CVS directories
find /tmp/oblig1-hpl -name CVS -print -exec rm -rf {} \;
# remove redundant files:
find /tmp/oblig1-hpl \( -name '*~' -o -name '*.bak' \
 -o -name '*.log' \) -print -exec rm -f {} \;
# pack files:
tar -cf oblig1-hpl.tar /tmp/tar/oblig1-hpl.tar
gzip oblig1-hpl.tar
# send oblig1-hpl.tar.gz as mail attachment
!ec
